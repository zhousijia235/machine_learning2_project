{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0875ffc4",
   "metadata": {},
   "source": [
    "## CNN Neural Network (Manual) For Cancerous and Non-Cancerous Cell Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d577035f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimal imports necessary for our manual implementation of CNN\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34761cf",
   "metadata": {},
   "source": [
    "## Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01fe611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sources:\n",
    "# Source - https://stackoverflow.com/a\n",
    "# Posted by Usama Aleem\n",
    "# Retrieved 2025-11-26, License - CC BY-SA 4.0\n",
    "# Used for saving images\n",
    "\n",
    "# https://medium.com/@maahip1304/the-complete-guide-to-image-preprocessing-techniques-in-python-dca30804550c\n",
    "# used to understand best image preprocessing practices\n",
    "import os, sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "'''\n",
    "Converting images in the directory to .npy format for usability in CNN model.\n",
    "We first load the image with cv2, grayscale it, then resize the image to a \n",
    "(256, 256) shape. We then normalize the number in a range of [0,1], and we \n",
    "apply a Gaussian blur to smooth the images. We then append this array to the\n",
    "x_train data to be converted to a npy file.\n",
    "'''\n",
    "\n",
    "def preprocess_images(chosen_dir: str):\n",
    "    path = '../data/cancer_dataset/lung_colon_image_set/'\n",
    "    path = path+chosen_dir\n",
    "    dirs = os.listdir( path )\n",
    "    dirs.sort()\n",
    "    for item in dirs:\n",
    "        image = cv2.imread(path+item)\n",
    "        gray_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "        gray_image = cv2.resize(gray_image, (256, 256))\n",
    "        blur_image = cv2.GaussianBlur(gray_image, (5,5), 0)\n",
    "        # create the directory where the data will be stored\n",
    "        dest_dir = os.path.join('reduced_cnn_data', chosen_dir)\n",
    "        os.makedirs(dest_dir, exist_ok=True)\n",
    "        out_path = os.path.join(dest_dir, item)\n",
    "        cv2.imwrite(out_path, blur_image)\n",
    "\n",
    "# do not run these, files already created\n",
    "# preprocess_images('colon_image_sets/colon_aca/')\n",
    "# preprocess_images('colon_image_sets/colon_n/')\n",
    "# preprocess_images('lung_image_sets/lung_aca/')\n",
    "# preprocess_images('lung_image_sets/lung_n/')\n",
    "# preprocess_images('lung_image_sets/lung_scc/')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab46f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sources:\n",
    "# Source - https://stackoverflow.com/a\n",
    "# Posted by Usama Aleem\n",
    "# Retrieved 2025-11-26, License - CC BY-SA 4.0\n",
    "# Used for learning to save images\n",
    "'''\n",
    "Convert our compress data to npy images\n",
    "'''\n",
    "\n",
    "def convert_to_npy(chosen_dir: str, filename: str):\n",
    "    path = 'reduced_cnn_data/'\n",
    "    path = path+chosen_dir\n",
    "    dirs = os.listdir( path )\n",
    "    dirs.sort()\n",
    "    x_train = []\n",
    "    for item in dirs:\n",
    "        image = cv2.imread(path+item)\n",
    "        img_array = np.array(image)\n",
    "        x_train.append(img_array)\n",
    "\n",
    "    # create the directory where the data will be stored\n",
    "    dest_dir = os.path.join('reduced_cnn_data/', 'npy/')\n",
    "    os.makedirs(dest_dir, exist_ok=True)\n",
    "    out_path = os.path.join(dest_dir, filename)\n",
    "    np.save(out_path, img_array)\n",
    "\n",
    "# convert_to_npy('colon_image_sets/colon_aca/', 'colon_aca.npy')\n",
    "# convert_to_npy('colon_image_sets/colon_n/', 'colon_n.npy')\n",
    "# convert_to_npy('lung_image_sets/lung_aca/', 'lung_aca.npy')\n",
    "# convert_to_npy('lung_image_sets/lung_n/', 'lung_n.npy')\n",
    "# convert_to_npy('lung_image_sets/lung_scc/', 'lung_scc.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e67f02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the npy files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5bd87940",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m image = cv2.imread(\u001b[33m'\u001b[39m\u001b[33mreduced_cnn_data/colon_image_sets/colon_aca/colonaca1.jpeg\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mimage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m)\n\u001b[32m      3\u001b[39m plt.imshow(image)\n\u001b[32m      4\u001b[39m plt.axis(\u001b[33m'\u001b[39m\u001b[33moff\u001b[39m\u001b[33m'\u001b[39m) \n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "image = cv2.imread('reduced_cnn_data/colon_image_sets/colon_aca/colonaca1.jpeg')\n",
    "print(image.shape)\n",
    "plt.imshow(image)\n",
    "plt.axis('off') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f40ff81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "colon_aca_data = np.load('reduced_cnn_data/colon_image_sets/colon_aca/npy/colon_aca.npy')\n",
    "print(colon_aca_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e02861a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(colon_aca_data)\n",
    "plt.axis('off') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3db15329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91317402 0.89898897 0.86639093 0.83746936 0.82879902 0.84022672\n",
      " 0.86207108 0.88704044 0.91023284 0.92567402 0.92984069 0.92371324\n",
      " 0.90713848 0.88235294 0.85928309 0.84080882 0.81954657 0.79552696\n",
      " 0.77971814 0.78180147 0.7953125  0.80042892 0.78927696 0.77760417\n",
      " 0.78207721 0.79347426 0.79543505 0.79381127 0.79613971 0.79451593\n",
      " 0.78262868 0.76473652 0.75174632 0.75015319 0.75710784 0.7734375\n",
      " 0.80358456 0.83336397 0.83645833 0.81302083 0.78688725 0.76458333\n",
      " 0.7294424  0.67196691 0.61363358 0.60376838 0.67166054 0.7700674\n",
      " 0.81240809 0.76976103 0.67742034 0.5810049  0.51188725 0.48125\n",
      " 0.51461397 0.62864583 0.74788603 0.78740809 0.76580882 0.73651961\n",
      " 0.71443015 0.69856005 0.68802083 0.67858456 0.66917892 0.6591299\n",
      " 0.64420956 0.61810662 0.58250613 0.55916054 0.56865809 0.60891544\n",
      " 0.66663603 0.72671569 0.77922794 0.82349877 0.8510723  0.84791667\n",
      " 0.81960784 0.78863358 0.77175245 0.76672794 0.75713848 0.73884804\n",
      " 0.72889093 0.7333027  0.73832721 0.73722426 0.73431373 0.73716299\n",
      " 0.75147059 0.76752451 0.77129289 0.76397059 0.74620098 0.71452206\n",
      " 0.67981005 0.65870098 0.65827206 0.67257966 0.68756127 0.69926471\n",
      " 0.7158701  0.73639706 0.74148284 0.70621936 0.63002451 0.55174632\n",
      " 0.50251225 0.46498162 0.41522672 0.37640931 0.40606618 0.52325368\n",
      " 0.67233456 0.77956495 0.81504289 0.80738358 0.80839461 0.82766544\n",
      " 0.83710172 0.83866422 0.86433824 0.91338848 0.95070466 0.96286765\n",
      " 0.96446078 0.96433824 0.96246936 0.96164216 0.96412377 0.96681985\n",
      " 0.96636029 0.96449142 0.96427696 0.96427696 0.96216299 0.95968137\n",
      " 0.9575674  0.95137868 0.93633578 0.90625    0.85153186 0.78186275\n",
      " 0.73823529 0.75526961 0.82147672 0.88688725 0.91590074 0.92144608\n",
      " 0.92879902 0.93982843 0.94534314 0.94074755 0.93180147 0.93045343\n",
      " 0.93694853 0.93802083 0.92582721 0.90324755 0.87506127 0.84019608\n",
      " 0.79056373 0.73731618 0.71654412 0.7333027  0.75153186 0.75309436\n",
      " 0.7495098  0.74911152 0.74816176 0.74249387 0.73826593 0.7484375\n",
      " 0.77340686 0.79341299 0.79439338 0.78802083 0.79090074 0.80407475\n",
      " 0.81464461 0.80870098 0.78624387 0.75       0.69852941 0.64908088\n",
      " 0.62328431 0.61703431 0.61871936 0.6236826  0.63458946 0.66773897\n",
      " 0.72965686 0.79613971 0.83716299 0.84353554 0.82797181 0.81011029\n",
      " 0.79497549 0.77659314 0.75814951 0.74708946 0.74451593 0.75306373\n",
      " 0.77634804 0.80860907 0.8307598  0.82074142 0.77276348 0.68661152\n",
      " 0.57310049 0.48967525 0.48768382 0.55055147 0.63961397 0.72653186\n",
      " 0.78630515 0.81026348 0.80768995 0.79503676 0.78973652 0.80431985\n",
      " 0.83615196 0.8698223  0.89454657 0.90260417 0.89065564 0.87454044\n",
      " 0.86721814 0.86482843 0.87742034 0.91354167 0.94764093 0.95625\n",
      " 0.94626225 0.93079044 0.90925245 0.8729473  0.82671569 0.79304534\n",
      " 0.78602941 0.80343137 0.83636642 0.86758578 0.86547181 0.77981005\n",
      " 0.5939951  0.40269608 0.33005515 0.39476103 0.54693627 0.69984681\n",
      " 0.75425858 0.73030025 0.71960784 0.72591912]\n"
     ]
    }
   ],
   "source": [
    "print(img_array[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f454677",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m lung_aca_data = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlung_aca.npy\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m lung_n_data = np.load(\u001b[33m'\u001b[39m\u001b[33mlung_n.npy\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      3\u001b[39m lung_scc_data = np.load(\u001b[33m'\u001b[39m\u001b[33mlung_scc.npy\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chris\\.pyenv\\pyenv-win\\versions\\3.11.7\\Lib\\site-packages\\numpy\\lib\\_npyio_impl.py:480\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[39m\n\u001b[32m    477\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mformat\u001b[39m.open_memmap(file, mode=mmap_mode,\n\u001b[32m    478\u001b[39m                                   max_header_size=max_header_size)\n\u001b[32m    479\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m                                 \u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m                                 \u001b[49m\u001b[43mmax_header_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_header_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    484\u001b[39m     \u001b[38;5;66;03m# Try a pickle\u001b[39;00m\n\u001b[32m    485\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_pickle:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chris\\.pyenv\\pyenv-win\\versions\\3.11.7\\Lib\\site-packages\\numpy\\lib\\format.py:829\u001b[39m, in \u001b[36mread_array\u001b[39m\u001b[34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001b[39m\n\u001b[32m    826\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    827\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m isfileobj(fp):\n\u001b[32m    828\u001b[39m         \u001b[38;5;66;03m# We can use the fast fromfile() function.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m829\u001b[39m         array = \u001b[43mnumpy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfromfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcount\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcount\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    830\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    831\u001b[39m         \u001b[38;5;66;03m# This is not a real file. We have to read it the\u001b[39;00m\n\u001b[32m    832\u001b[39m         \u001b[38;5;66;03m# memory-intensive way.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    840\u001b[39m         \u001b[38;5;66;03m# not correctly instantiate zero-width string dtypes; see\u001b[39;00m\n\u001b[32m    841\u001b[39m         \u001b[38;5;66;03m# https://github.com/numpy/numpy/pull/6430\u001b[39;00m\n\u001b[32m    842\u001b[39m         array = numpy.ndarray(count, dtype=dtype)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "lung_aca_data = np.load('lung_aca.npy')\n",
    "lung_n_data = np.load('lung_n.npy')\n",
    "lung_scc_data = np.load('lung_scc.npy')\n",
    "\n",
    "colon_aca_data = np.load('colon_aca.npy')\n",
    "colon_n_data = np.load('colon_n.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bb638d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16edbb7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
